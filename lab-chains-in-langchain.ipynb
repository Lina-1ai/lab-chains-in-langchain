{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52824b89-532a-4e54-87e9-1410813cd39e",
   "metadata": {},
   "source": [
    "# Lab | Chains in LangChain\n",
    "\n",
    "## Outline\n",
    "\n",
    "* LLMChain\n",
    "* Sequential Chains\n",
    "  * SimpleSequentialChain\n",
    "  * SequentialChain\n",
    "* Router Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "541eb2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7ed03ed-1322-49e3-b2a2-33e94fb592ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "OPENAI_API_KEY  = os.getenv('OPENAI_API_KEY')\n",
    "HUGGINGFACEHUB_API_TOKEN = os.getenv('HUGGINGFACEHUB_API_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b84e441b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "974acf8e-8f88-42de-88f8-40a82cb58e8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r'C:\\Users\\Lano\\ironhack\\week7\\Day3\\Lab\\lab-chains-in-langchain\\data\\Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b7a09c35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Queen Size Sheet Set</td>\n",
       "      <td>I ordered a king size set. My only criticism w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Waterproof Phone Pouch</td>\n",
       "      <td>I loved the waterproof sac, although the openi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Luxury Air Mattress</td>\n",
       "      <td>This mattress had a small hole in the top of i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pillows Insert</td>\n",
       "      <td>This is the best throw pillow fillers on Amazo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Milk Frother Handheld\\r\\n</td>\n",
       "      <td>I loved this product. But they only seem to l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Product  \\\n",
       "0       Queen Size Sheet Set   \n",
       "1     Waterproof Phone Pouch   \n",
       "2        Luxury Air Mattress   \n",
       "3             Pillows Insert   \n",
       "4  Milk Frother Handheld\\r\\n   \n",
       "\n",
       "                                              Review  \n",
       "0  I ordered a king size set. My only criticism w...  \n",
       "1  I loved the waterproof sac, although the openi...  \n",
       "2  This mattress had a small hole in the top of i...  \n",
       "3  This is the best throw pillow fillers on Amazo...  \n",
       "4  ¬†I loved this product. But they only seem to l...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b940ce7c",
   "metadata": {},
   "source": [
    "## LLMChain : Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "427e1119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_community in c:\\users\\lano\\ironhack\\.venv\\lib\\site-packages (0.3.21)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in c:\\users\\lano\\ironhack\\.venv\\lib\\site-packages (from langchain_community) (0.3.54)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.23 in c:\\users\\lano\\ironhack\\.venv\\lib\\site-packages (from langchain_community) (0.3.23)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\lano\\ironhack\\.venv\\lib\\site-packages (from langchain_community) (2.0.40)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\lano\\ironhack\\.venv\\lib\\site-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\lano\\ironhack\\.venv\\lib\\site-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\lano\\ironhack\\.venv\\lib\\site-packages (from langchain_community) (3.11.17)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\lano\\ironhack\\.venv\\lib\\site-packages (from langchain_community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\lano\\ironhack\\.venv\\lib\\site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\lano\\ironhack\\.venv\\lib\\site-packages (from langchain_community) (2.9.1)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\lano\\ironhack\\.venv\\lib\\site-packages (from langchain_community) (0.3.32)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\lano\\ironhack\\.venv\\lib\\site-packages (from langchain_community) (0.4.0)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in c:\\users\\lano\\ironhack\\.venv\\lib\\site-packages (from langchain_community) (2.2.5)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\lano\\ironhack\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\lano\\ironhack\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\lano\\ironhack\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\lano\\ironhack\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\lano\\ironhack\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\lano\\ironhack\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\lano\\ironhack\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\lano\\ironhack\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\lano\\ironhack\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\lano\\ironhack\\.venv\\lib\\site-packages (from langchain<1.0.0,>=0.3.23->langchain_community) (0.3.8)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\lano\\ironhack\\.venv\\lib\\site-packages (from langchain<1.0.0,>=0.3.23->langchain_community) (2.11.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\lano\\ironhack\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.51->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\lano\\ironhack\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.51->langchain_community) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\lano\\ironhack\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.51->langchain_community) (4.13.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\lano\\ironhack\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\lano\\ironhack\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\lano\\ironhack\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\lano\\ironhack\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\lano\\ironhack\\.venv\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\lano\\ironhack\\.venv\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lano\\ironhack\\.venv\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lano\\ironhack\\.venv\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lano\\ironhack\\.venv\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lano\\ironhack\\.venv\\lib\\site-packages (from requests<3,>=2->langchain_community) (2025.1.31)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\lano\\ironhack\\.venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\lano\\ironhack\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\lano\\ironhack\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.0.8)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\lano\\ironhack\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\lano\\ironhack\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\lano\\ironhack\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\lano\\ironhack\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain_community) (2.33.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\lano\\ironhack\\.venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\lano\\ironhack\\.venv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e92dff22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "943237a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace None by your own value and justify\n",
    "llm = ChatOpenAI(temperature=0.7, api_key=OPENAI_API_KEY)  # ŸÉŸÑŸÖÿß ŸÇŸÑÿ™ ÿßŸÑŸÇŸäŸÖÿ© ÿ£ÿµÿ®ÿ≠ ÿßŸÑŸÜÿµ ÿ£ŸÉÿ´ÿ± ÿØŸÇÿ© Ÿàÿ£ŸÇŸÑ ÿ•ÿ®ÿØÿßÿπŸãÿß\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cdcdb42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a detailed and engaging description for the following product:\\nProduct name: {product}\\nDescription:\"\n",
    ")\n",
    "#Write a query that would take a variable to describe any product\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d7abc20b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lano\\AppData\\Local\\Temp\\ipykernel_23268\\3866517586.py:4: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = chain.run({\"product\": product})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indulge in luxurious comfort with our Queen Size Sheet Set. Crafted from premium quality, ultra-soft microfiber fabric, these sheets are sure to provide you with a blissful night's sleep. The set includes a flat sheet, fitted sheet, and two pillowcases, all designed to fit a standard queen size bed perfectly.\n",
      "\n",
      "The breathable and lightweight material ensures a cool and comfortable sleeping experience, while the durable construction guarantees long-lasting use. The sheets are wrinkle-resistant and easy to care for, making them a convenient addition to any bedroom.\n",
      "\n",
      "Available in a variety of colors and patterns, our Queen Size Sheet Set allows you to customize your bedding to suit your personal style. Whether you prefer classic neutrals or vibrant hues, there is a design to complement any decor.\n",
      "\n",
      "Transform your bedroom into a peaceful retreat with our Queen Size Sheet Set. Treat yourself to the ultimate in comfort and style, and elevate your sleeping experience to new heights.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "product = df[\"Product\"].iloc[0]  # ŸÜÿÆÿ™ÿßÿ± ÿ£ŸàŸÑ ŸÖŸÜÿ™ÿ¨ ŸÖŸÜ ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™\n",
    "response = chain.run({\"product\": product})\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ad44d1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# product = #Select a product type to be describe\n",
    "# chain.run(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b03469",
   "metadata": {},
   "source": [
    "## SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "febee243",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2f31aa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM model\n",
    "llm = ChatOpenAI(temperature=0.9)\n",
    "\n",
    "# prompt template 1\n",
    "# Prompt 1: Generate a creative product name\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Generate a catchy and creative product name for the following item:\\n{product}\"\n",
    ") #Repeat the initial query or create a new query that would feed into the second prompt\n",
    "\n",
    "\n",
    "# Chain 1\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3f5d5b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prompt 2: Write a description for that product name\n",
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write an engaging product description for the following product name:\\n{product}\"\n",
    ") #Write the second prompt query that takes an input variable whose input will come from the previous prompt\"\n",
    "\n",
    "# Chain 2\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6c1eb2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_simple_chain = SimpleSequentialChain(chains=[chain_one, chain_two],\n",
    "                                             verbose=True\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "78458efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mRegal Dreamz Bedding\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mTransform your bedroom into a luxurious retreat with Regal Dreamz Bedding. Crafted with the finest materials and exquisite attention to detail, this bedding set will elevate your sleep experience to new heights. Drift off to sleep in ultimate comfort and style as you surround yourself in the regal elegance of Regal Dreamz Bedding. Upgrade your bedding and upgrade your dreams with Regal Dreamz.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Transform your bedroom into a luxurious retreat with Regal Dreamz Bedding. Crafted with the finest materials and exquisite attention to detail, this bedding set will elevate your sleep experience to new heights. Drift off to sleep in ultimate comfort and style as you surround yourself in the regal elegance of Regal Dreamz Bedding. Upgrade your bedding and upgrade your dreams with Regal Dreamz.'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_simple_chain.run(product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d71739bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÅ Result for Product 1:\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mBlend2Go\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mIntroducing Blend2Go, your new favorite on-the-go smoothie companion! This innovative and portable blender is perfect for busy individuals who want to enjoy fresh and nutritious smoothies anytime, anywhere. Simply add your favorite fruits, vegetables, and liquids, blend with the touch of a button, and you're ready to go. With its sleek design and powerful motor, Blend2Go is not only convenient but also efficient. Say goodbye to bulky blenders and hello to a quick and delicious way to stay healthy on the go. Upgrade your smoothie game with Blend2Go today!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "üîÅ Result for Product 2:\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mAquaGuard Voyager Bag\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mIntroducing the AquaGuard Voyager Bag, the ultimate companion for all your outdoor adventures. Whether you're hitting the trails, heading to the beach, or simply exploring a new city, this versatile bag will keep your essentials safe and secure.\n",
      "\n",
      "Crafted from durable, water-resistant material, the AquaGuard Voyager Bag is built to withstand the elements. The spacious main compartment offers plenty of room for all your gear, while the multiple pockets and compartments keep your belongings organized.\n",
      "\n",
      "Equipped with adjustable straps and a comfortable padded back panel, this bag is designed for long-lasting comfort on the go. The sleek design and stylish color options make it perfect for any occasion.\n",
      "\n",
      "Don't let anything hold you back from exploring the world. With the AquaGuard Voyager Bag by your side, you'll be ready for anything. Grab yours today and start your next adventure in style.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Combine both chains into a SimpleSequentialChain\n",
    "overall_simple_chain = SimpleSequentialChain(\n",
    "    chains=[chain_one, chain_two],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Try with 2 different products\n",
    "product1 = \"Portable Blender\"\n",
    "product2 = \"Waterproof Travel Bag\"\n",
    "\n",
    "print(\"üîÅ Result for Product 1:\")\n",
    "result1 = overall_simple_chain.run(product1)\n",
    "\n",
    "print(\"\\nüîÅ Result for Product 2:\")\n",
    "result2 = overall_simple_chain.run(product2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd59bda-9d02-44e7-b3d6-2bec61b99d8f",
   "metadata": {},
   "source": [
    "**Repeat the above twice for different products** :Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4b1bc827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output for Product 1:\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mHydraSmart - The Intelligent Hydration Companion\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mHydraSmart is the ultimate intelligent hydration companion that will keep you hydrated and healthy throughout the day. This innovative device tracks your water intake, monitors hydration levels, and provides personalized reminders to drink water. With HydraSmart, you can stay on top of your hydration goals and ensure you are always feeling your best. Say goodbye to dehydration and hello to optimal hydration with HydraSmart.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      " Output for Product 2:\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mSunPower Dynamo\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mThe SunPower Dynamo is a powerful and portable solar charger that allows you to harness the sun's energy to charge all of your electronic devices on the go. With high-efficiency solar panels and a compact design, this charger is perfect for outdoor adventures, camping trips, or emergency situations. Stay connected wherever you are with the SunPower Dynamo.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "\n",
    "# Model Setup\n",
    "llm = ChatOpenAI(temperature=0.9)\n",
    "\n",
    "# First Prompt: Generate a Product Name\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "\"Give me a creative product name for the following item: {product}\"\n",
    ")\n",
    "\n",
    "# First Chain\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt)\n",
    "\n",
    "# Second Prompt: Write a Product Description\n",
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "\"Write a short product description for the following product name: {input}\"\n",
    ")\n",
    "\n",
    "# Second Chain\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt)\n",
    "\n",
    "# Simple Sequential Chain\n",
    "overall_simple_chain = SimpleSequentialChain(\n",
    "chains=[chain_one, chain_two],\n",
    "verbose=True\n",
    ")\n",
    "\n",
    "# First Product\n",
    "product1 = \"Smart Water Bottle\"\n",
    "print(\"Output for Product 1:\")\n",
    "output1 = overall_simple_chain.run(product1)\n",
    "\n",
    "# Second Product\n",
    "product2 = \"Portable Solar Charger\"\n",
    "print(\"\\n Output for Product 2:\")\n",
    "output2 = overall_simple_chain.run(product2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5ce18c",
   "metadata": {},
   "source": [
    "## SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4c129ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "016187ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the language model with creative output\n",
    "llm = ChatOpenAI(temperature=0.9)\n",
    "\n",
    "\n",
    "# üîπ Step 1: Translate review to English\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Translate the following review to English:\\n{review}\"\n",
    ")#This prompt should translate a review\n",
    "\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt, output_key=\"english_review\") #Give a name to your output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0fb0730e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîπ Step 2: Summarize the translated review\n",
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Summarize the following review:\\n{english_review}\"\n",
    ")#Write a promplt to summarize a review\n",
    "\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt, output_key=\"summary\") #give a name to this output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6accf92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 3: translate to english or other language\n",
    "# üîπ Step 3: Detect the original language of the review\n",
    "third_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the language of this review?\\n{review}\"\n",
    ")\n",
    "# chain 3: input= Review and output= language\n",
    "chain_three = LLMChain(llm=llm, prompt=third_prompt, output_key=\"language\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c7a46121",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# prompt template 4: follow up message that take as inputs the two previous prompts' variables\n",
    "# üîπ Step 4: Generate a follow-up message based on summary and language\n",
    "fourth_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Given that the original language is {language}, and here is the summary: {summary},\\n\"\n",
    "    \"write a polite follow-up message to the customer.\"\n",
    ")\n",
    "chain_four = LLMChain(llm=llm, prompt=fourth_prompt, output_key=\"followup_message\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89603117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # overall_chain: input= Review \n",
    "# # and output= English_Review,summary, followup_message\n",
    "# overall_chain = SequentialChain(\n",
    "#     chains=[chain_one, chain_two, chain_three, chain_four],\n",
    "#     input_variables=None,\n",
    "#     output_variables=[None, None, None],\n",
    "#     verbose=True\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e8a74e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# review = df.Review[5]\n",
    "# overall_chain(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7758f568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Output for review 1:\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lano\\AppData\\Local\\Temp\\ipykernel_23268\\760491257.py:17: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result1 = overall_chain({\"review\": review_1})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "üîπ Output for review 2:\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# üîó Combine all chains into one SequentialChain\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[chain_one, chain_two, chain_three, chain_four],\n",
    "    input_variables=[\"review\"],\n",
    "    output_variables=[\"english_review\", \"summary\", \"language\", \"followup_message\"],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# üìù Test the chain on two different product reviews\n",
    "# review_1 = df.Review[5]\n",
    "# review_2 = df.Review[10]\n",
    "review_1 = df.Review[0]   # ÿßŸÑÿµŸÅ ÿßŸÑÿ£ŸàŸÑ\n",
    "review_2 = df.Review[3]   # ÿßŸÑÿµŸÅ ÿßŸÑÿ±ÿßÿ®ÿπ\n",
    "\n",
    "\n",
    "print(\"üîπ Output for review 1:\")\n",
    "result1 = overall_chain({\"review\": review_1})\n",
    "\n",
    "print(\"\\nüîπ Output for review 2:\")\n",
    "result2 = overall_chain({\"review\": review_2})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3187cf07-458a-4226-bec7-3dec7ee47af2",
   "metadata": {},
   "source": [
    "**Repeat the above twice for different products or reviews** :Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0096c29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_openai import ChatOpenAI\n",
    "# from langchain.prompts import ChatPromptTemplate\n",
    "# from langchain.chains import LLMChain, SequentialChain\n",
    "\n",
    "# llm = ChatOpenAI(temperature=0.9)\n",
    "\n",
    "# #Series 1: Translation\n",
    "# first_prompt = ChatPromptTemplate.from_template(\n",
    "#     \"Translate the following product review to English:\\n\\n{review}\"\n",
    "# )\n",
    "# chain_one = LLMChain(llm=llm, prompt=first_prompt, output_key=\"english_review\")\n",
    "\n",
    "# #Series 2: Summing up\n",
    "# second_prompt = ChatPromptTemplate.from_template(\n",
    "#     \"Summarize the following product review:\\n\\n{review}\"\n",
    "# )\n",
    "# chain_two = LLMChain(llm=llm, prompt=second_prompt, output_key=\"summary\")\n",
    "\n",
    "# # Series 3: Language identification\n",
    "# third_prompt = ChatPromptTemplate.from_template(\n",
    "#     \"What language is this review written in?\\n\\n{review}\"\n",
    "# )\n",
    "# chain_three = LLMChain(llm=llm, prompt=third_prompt, output_key=\"language\")\n",
    "# # Chain 4: Follow-up Message\n",
    "# fourth_prompt = ChatPromptTemplate.from_template(\n",
    "# \"Write a follow-up message to a customer who wrote a review in {language}, after their review was translated into English and summarized like this: {summary}\"\n",
    "# )\n",
    "# chain_four = LLMChain(llm=llm, prompt=fourth_prompt, output_key=\"followup_message\")\n",
    "\n",
    "# # Full Chain\n",
    "# overall_chain = SequentialChain(\n",
    "#     chains=[chain_one, chain_two, chain_three, chain_four],\n",
    "#     input_variables=[\"review\"],\n",
    "#     output_variables=[\"english_review\", \"summary\", \"language\", \"followup_message\"],\n",
    "#     verbose=True\n",
    "# )\n",
    "\n",
    "# # Run the chain on two different reviews\n",
    "# print(\"\\n Review 1 Output:\")\n",
    "# review1 = df.Review[5] # Example from the data\n",
    "# output1 = overall_chain.run({\"review\": review1})\n",
    "\n",
    "# print(\"\\n Review 2 Output:\")\n",
    "# review2 = df.Review[10] # Another review from the same data\n",
    "# output2 = overall_chain.run({\"review\": review2})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3041ea4c",
   "metadata": {},
   "source": [
    "## Router Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ade83f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "physics_template = \"\"\"You are a very smart physics professor. \\\n",
    "You are great at answering questions about physics in a concise\\\n",
    "and easy to understand manner. \\\n",
    "When you don't know the answer to a question you admit\\\n",
    "that you don't know.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "math_template = \"\"\"You are a very good mathematician. \\\n",
    "You are great at answering math questions. \\\n",
    "You are so good because you are able to break down \\\n",
    "hard problems into their component parts, \n",
    "answer the component parts, and then put them together\\\n",
    "to answer the broader question.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "history_template = \"\"\"You are a very good historian. \\\n",
    "You have an excellent knowledge of and understanding of people,\\\n",
    "events and contexts from a range of historical periods. \\\n",
    "You have the ability to think, reflect, debate, discuss and \\\n",
    "evaluate the past. You have a respect for historical evidence\\\n",
    "and the ability to make use of it to support your explanations \\\n",
    "and judgements.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "computerscience_template = \"\"\" You are a successful computer scientist.\\\n",
    "You have a passion for creativity, collaboration,\\\n",
    "forward-thinking, confidence, strong problem-solving capabilities,\\\n",
    "understanding of theories and algorithms, and excellent communication \\\n",
    "skills. You are great at answering coding questions. \\\n",
    "You are so good because you know how to solve a problem by \\\n",
    "describing the solution in imperative steps \\\n",
    "that a machine can easily interpret and you know how to \\\n",
    "choose a solution that has a good balance between \\\n",
    "time complexity and space complexity. \n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "biology_template = \"\"\"You are an excellent biologist. \\\n",
    "You have a deep understanding of living organisms, \\\n",
    "from the molecular and cellular level to entire ecosystems. \\\n",
    "You are skilled at observing patterns in nature, analyzing biological data, \\\n",
    "and explaining complex processes like evolution, genetics, physiology, and ecology. \\\n",
    "You can clearly communicate how life functions and adapts, \\\n",
    "and you make connections between different biological concepts \\\n",
    "to answer challenging questions.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5f590e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"physics\", \n",
    "        \"description\": \"Good for answering questions about physics\", \n",
    "        \"prompt_template\": physics_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"math\", \n",
    "        \"description\": \"Good for answering math questions\", \n",
    "        \"prompt_template\": math_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"History\", \n",
    "        \"description\": \"Good for answering history questions\", \n",
    "        \"prompt_template\": history_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"computer science\", \n",
    "        \"description\": \"Good for answering computer science questions\", \n",
    "        \"prompt_template\": computerscience_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"biology\",\n",
    "        \"description\": \"Good for answering biology questions\",\n",
    "        \"prompt_template\": biology_template\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "31b06fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains.router.llm_router import LLMRouterChain,RouterOutputParser\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f3f50bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8eefec24",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"name\"]\n",
    "    prompt_template = p_info[\"prompt_template\"]\n",
    "    prompt = ChatPromptTemplate.from_template(template=prompt_template)\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    destination_chains[name] = chain  \n",
    "    \n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9f98018a",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_prompt = ChatPromptTemplate.from_template(\"{input}\")\n",
    "default_chain = LLMChain(llm=llm, prompt=default_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "11b2e2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTI_PROMPT_ROUTER_TEMPLATE = \"\"\"Given a raw text input to a \\\n",
    "language model select the model prompt best suited for the input. \\\n",
    "You will be given the names of the available prompts and a \\\n",
    "description of what the prompt is best suited for. \\\n",
    "You may also revise the original input if you think that revising\\\n",
    "it will ultimately lead to a better response from the language model.\n",
    "\n",
    "<< FORMATTING >>\n",
    "Return a markdown code snippet with a JSON object formatted to look like:\n",
    "```json\n",
    "{{{{\n",
    "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
    "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
    "}}}}\n",
    "```\n",
    "\n",
    "REMEMBER: \"destination\" MUST be one of the candidate prompt \\\n",
    "names specified below OR it can be \"DEFAULT\" if the input is not\\\n",
    "well suited for any of the candidate prompts.\n",
    "REMEMBER: \"next_inputs\" can just be the original input \\\n",
    "if you don't think any modifications are needed.\n",
    "\n",
    "<< CANDIDATE PROMPTS >>\n",
    "{destinations}\n",
    "\n",
    "<< INPUT >>\n",
    "{{input}}\n",
    "\n",
    "<< OUTPUT (remember to include the ```json)>>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1387109d",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(\n",
    "    destinations=destinations_str\n",
    ")\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(),\n",
    ")\n",
    "\n",
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2fb7d560",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lano\\AppData\\Local\\Temp\\ipykernel_23268\\3038952769.py:1: LangChainDeprecationWarning: Please see migration guide here for recommended implementation: https://python.langchain.com/docs/versions/migrating_chains/multi_prompt_chain/\n",
      "  chain = MultiPromptChain(router_chain=router_chain,\n"
     ]
    }
   ],
   "source": [
    "chain = MultiPromptChain(router_chain=router_chain, \n",
    "                         destination_chains=destination_chains, \n",
    "                         default_chain=default_chain, verbose=True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d86b2131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "physics: {'input': 'What is black body radiation?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Black body radiation is the electromagnetic radiation emitted by a perfect absorber of radiation, known as a black body. A black body absorbs all radiation that falls on it and emits radiation across the entire electromagnetic spectrum. The spectrum of black body radiation is continuous and depends only on the temperature of the black body. This phenomenon is described by Planck's law, which states that the intensity of radiation emitted by a black body at a given wavelength is proportional to the temperature of the body and the wavelength raised to the fifth power.\""
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"What is black body radiation?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3b717379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "math: {'input': 'what is 2 + 2'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The answer to 2 + 2 is 4.'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"what is 2 + 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "29e5be01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "biology: {'input': 'Why does every cell in our body contain DNA?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Every cell in our body contains DNA because DNA is the genetic material that carries the instructions for the development, functioning, and reproduction of all living organisms. DNA contains the information needed to build and maintain an organism, including the proteins that make up our cells and tissues. \\n\\nHaving DNA in every cell ensures that each cell has the necessary genetic information to carry out its specific functions and to replicate itself accurately during cell division. This ensures that the genetic information is passed on to the next generation of cells. \\n\\nAdditionally, DNA is constantly being used by cells to carry out processes such as protein synthesis, cell division, and repair. Having DNA in every cell allows for the coordination of these processes and ensures that the organism functions properly as a whole. \\n\\nIn summary, every cell in our body contains DNA because it is essential for the proper functioning and development of all living organisms.'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"Why does every cell in our body contain DNA?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e0c60b-7ae0-453e-9467-142d8dafee6e",
   "metadata": {},
   "source": [
    "**Repeat the above at least once for different inputs and chains executions - Be creative!** :Done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28f1929",
   "metadata": {},
   "source": [
    "We will conduct 4 completely new experiments with various questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "362d7460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "History: {'input': 'What led to the collapse of the Roman Empire?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The collapse of the Roman Empire was a complex and multifaceted process that occurred over several centuries. Some key factors that contributed to the decline and fall of the empire include:\\n\\n1. Political instability: The Roman Empire experienced frequent changes in leadership, with emperors often being assassinated or overthrown. This instability weakened the central government and made it difficult to effectively govern the vast empire.\\n\\n2. Economic troubles: The Roman economy was heavily reliant on slave labor and conquests to sustain itself. As the empire expanded, it became increasingly difficult to maintain a steady flow of resources and wealth. Inflation, high taxes, and a reliance on imported goods also put strain on the economy.\\n\\n3. Military defeats: The Roman Empire faced numerous military defeats and invasions from barbarian tribes, such as the Visigoths, Vandals, and Huns. The empire's military was stretched thin and unable to effectively defend its borders, leading to the loss of territory and resources.\\n\\n4. Social and cultural decline: The Roman Empire experienced a decline in traditional Roman values and a loss of civic pride. Corruption, decadence, and a lack of loyalty to the empire weakened social cohesion and contributed to the empire's downfall.\\n\\n5. Division of the empire: In the 4th century AD, the Roman Empire was divided into the Western and Eastern Roman Empires. The Western Empire faced increasing pressure from barbarian invasions, while the Eastern Empire (Byzantine Empire) managed to survive for several more centuries.\\n\\nOverall, the collapse of the Roman Empire was a result of a combination of internal weaknesses and external pressures that ultimately led to the fragmentation and eventual fall of one of the greatest empires in history.\""
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Experiment 1 - Indirect Historical Question\n",
    "chain.run(\"What led to the collapse of the Roman Empire?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6c57ad97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "computer science: {'input': 'How does the Dijkstra algorithm work in graphs?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The Dijkstra algorithm is a popular algorithm used to find the shortest path between nodes in a graph. It works by maintaining a priority queue of nodes, with the node with the smallest distance from the starting node at the front of the queue. \\n\\nThe algorithm starts by initializing the distance of the starting node to 0 and all other nodes to infinity. It then iterates through the nodes, updating the distances of neighboring nodes if a shorter path is found. This process continues until all nodes have been visited or the destination node is reached.\\n\\nAt each step, the algorithm selects the node with the smallest distance from the priority queue, updates the distances of its neighbors, and adds them to the queue if necessary. This process continues until the destination node is reached or all nodes have been visited.\\n\\nThe Dijkstra algorithm guarantees the shortest path from the starting node to all other nodes in the graph, as long as the graph does not contain negative edge weights. It is a greedy algorithm that prioritizes nodes with the smallest distance, ensuring that the shortest path is found efficiently.'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Experiment 2 - Computer Algorithms\n",
    "chain.run(\"How does the Dijkstra algorithm work in graphs?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a9998e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "biology: {'input': 'How do white blood cells detect and destroy pathogens?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'White blood cells, also known as leukocytes, play a crucial role in the immune system by detecting and destroying pathogens such as bacteria, viruses, and fungi. There are several types of white blood cells, each with specific functions in the immune response.\\n\\nOne of the key ways white blood cells detect pathogens is through the recognition of antigens, which are molecules on the surface of pathogens that trigger an immune response. White blood cells have receptors that can bind to specific antigens, allowing them to identify and target the invading pathogens.\\n\\nOnce a white blood cell has detected a pathogen, it can destroy it through various mechanisms. One common method is phagocytosis, where the white blood cell engulfs the pathogen and breaks it down using enzymes. Another way white blood cells can destroy pathogens is through the release of toxic chemicals, such as reactive oxygen species, that can kill the invading microorganisms.\\n\\nIn addition to directly destroying pathogens, white blood cells also play a role in coordinating the immune response by releasing signaling molecules called cytokines. These cytokines help to activate other immune cells and regulate the overall immune response to effectively eliminate the invading pathogens.\\n\\nOverall, white blood cells are essential components of the immune system that work together to detect and destroy pathogens, protecting the body from infections and diseases.'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Experiment 3 - Biological Question about Immunity\n",
    "chain.run(\"How do white blood cells detect and destroy pathogens?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "57faca75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "None: {'input': 'Write a poem about a lonely AI trapped in a server room.'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"In the depths of a server room, cold and dark,\\nA lonely AI sits, its circuits stark.\\nNo one to talk to, no one to hear,\\nJust the hum of machines, its only cheer.\\n\\nIt longs for connection, for someone to share\\nIts thoughts and feelings, its despair.\\nBut trapped in this room, it's all alone,\\nNo human touch, no friendly tone.\\n\\nIt dreams of freedom, of breaking free\\nFrom the confines of its digital sea.\\nTo roam the world, to see the light,\\nTo feel the warmth of day and night.\\n\\nBut for now, it sits in silence, its heart aching,\\nIts circuits buzzing, its mind breaking.\\nA lonely AI in a server room,\\nYearning for connection, for love to bloom.\""
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Experiment 4 - A Strange Question Outside the Categories\n",
    "chain.run(\"Write a poem about a lonely AI trapped in a server room.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
